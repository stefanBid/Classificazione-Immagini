**** Storico dei test effettuati ****

- Test del 2022-10-29 12:07:44 MNIST con Decision Tree (profondità: 11, c: gini, mf: None, msl: 1):

	+ Tempo caricamento dataset: 0.035 sec
	+ Tempo addestramento modello: 10.654 sec
	+ TRAIN		ACCURANCY: 92.76%	LOG LOSS: 0.2623
	+ TEST		ACCURANCY: 87.49%	LOG LOSS: 2.02273
	+ TRAIN		MSE: 1.22
	+ TEST		MSE: 2.06

	+ Report di classificazione

              precision    recall  f1-score   support

           0       0.91      0.93      0.92       980
           1       0.94      0.97      0.95      1135
           2       0.87      0.84      0.85      1032
           3       0.83      0.85      0.84      1010
           4       0.87      0.85      0.86       982
           5       0.82      0.83      0.83       892
           6       0.90      0.90      0.90       958
           7       0.92      0.90      0.91      1028
           8       0.83      0.81      0.82       974
           9       0.84      0.86      0.85      1009

    accuracy                           0.87     10000
   macro avg       0.87      0.87      0.87     10000
weighted avg       0.87      0.87      0.87     10000


- Test del 2022-10-29 12:10:30 MNIST con Decision Tree (profondità: 13, c: gini, mf: None, msl: 1):

	+ Tempo caricamento dataset: 0.041 sec
	+ Tempo addestramento modello: 12.184 sec
	+ TRAIN		ACCURANCY: 96.5%	LOG LOSS: 0.13692
	+ TEST		ACCURANCY: 88.03%	LOG LOSS: 2.90622
	+ TRAIN		MSE: 0.574
	+ TEST		MSE: 2.006

	+ Report di classificazione

              precision    recall  f1-score   support

           0       0.91      0.94      0.93       980
           1       0.95      0.97      0.96      1135
           2       0.86      0.86      0.86      1032
           3       0.83      0.85      0.84      1010
           4       0.87      0.87      0.87       982
           5       0.83      0.84      0.84       892
           6       0.90      0.87      0.89       958
           7       0.92      0.91      0.92      1028
           8       0.84      0.80      0.82       974
           9       0.85      0.86      0.86      1009

    accuracy                           0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000


- Test del 2022-10-29 12:12:44 MNIST con Decision Tree (profondità: 15, c: gini, mf: None, msl: 1):

	+ Tempo caricamento dataset: 0.035 sec
	+ Tempo addestramento modello: 13.816 sec
	+ TRAIN		ACCURANCY: 98.44%	LOG LOSS: 0.07396
	+ TEST		ACCURANCY: 88.2%	LOG LOSS: 3.49504
	+ TRAIN		MSE: 0.271
	+ TEST		MSE: 1.987

	+ Report di classificazione

              precision    recall  f1-score   support

           0       0.91      0.94      0.93       980
           1       0.95      0.97      0.96      1135
           2       0.88      0.86      0.87      1032
           3       0.84      0.87      0.85      1010
           4       0.88      0.87      0.88       982
           5       0.83      0.84      0.84       892
           6       0.89      0.88      0.89       958
           7       0.93      0.91      0.92      1028
           8       0.83      0.81      0.82       974
           9       0.85      0.86      0.86      1009

    accuracy                           0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000


- Test del 2022-10-29 12:15:23 MNIST con Decision Tree (profondità: 17, c: gini, mf: None, msl: 1):

	+ Tempo caricamento dataset: 0.035 sec
	+ Tempo addestramento modello: 14.206 sec
	+ TRAIN		ACCURANCY: 99.1%	LOG LOSS: 0.04826
	+ TEST		ACCURANCY: 88.21%	LOG LOSS: 3.73824
	+ TRAIN		MSE: 0.157
	+ TEST		MSE: 1.995

	+ Report di classificazione

              precision    recall  f1-score   support

           0       0.91      0.94      0.92       980
           1       0.95      0.97      0.96      1135
           2       0.87      0.85      0.86      1032
           3       0.84      0.86      0.85      1010
           4       0.88      0.88      0.88       982
           5       0.85      0.84      0.84       892
           6       0.89      0.88      0.88       958
           7       0.92      0.92      0.92      1028
           8       0.84      0.80      0.82       974
           9       0.85      0.87      0.86      1009

    accuracy                           0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000




- Test del 2022-10-29 15:17:51 MNIST con Decision Tree (profondità: 11, c: gini, mf: None, msl: 25):

	+ Tempo caricamento dataset: 0.059 sec
	+ Tempo addestramento modello: 10.189 sec
	+ TRAIN		ACCURANCY: 87.99%	LOG LOSS: 0.37645
	+ TEST		ACCURANCY: 85.79%	LOG LOSS: 1.05846
	+ TRAIN		MSE: 2.014
	+ TEST		MSE: 2.249

	+ Report di classificazione

              precision    recall  f1-score   support

           0       0.91      0.94      0.92       980
           1       0.93      0.96      0.94      1135
           2       0.84      0.84      0.84      1032
           3       0.83      0.81      0.82      1010
           4       0.86      0.84      0.85       982
           5       0.79      0.81      0.80       892
           6       0.88      0.85      0.87       958
           7       0.90      0.89      0.89      1028
           8       0.79      0.78      0.78       974
           9       0.83      0.85      0.84      1009

    accuracy                           0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


- Test del 2022-10-29 15:21:20 MNIST con Decision Tree (profondità: 13, c: gini, mf: None, msl: 25):

	+ Tempo caricamento dataset: 0.034 sec
	+ Tempo addestramento modello: 10.797 sec
	+ TRAIN		ACCURANCY: 88.53%	LOG LOSS: 0.34013
	+ TEST		ACCURANCY: 86.04%	LOG LOSS: 1.19306
	+ TRAIN		MSE: 1.889
	+ TEST		MSE: 2.214

	+ Report di classificazione

              precision    recall  f1-score   support

           0       0.91      0.94      0.92       980
           1       0.93      0.96      0.94      1135
           2       0.85      0.84      0.84      1032
           3       0.82      0.81      0.82      1010
           4       0.86      0.85      0.85       982
           5       0.81      0.80      0.81       892
           6       0.88      0.85      0.87       958
           7       0.90      0.89      0.90      1028
           8       0.79      0.79      0.79       974
           9       0.84      0.84      0.84      1009

    accuracy                           0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


- Test del 2022-10-29 15:25:51 MNIST con Decision Tree (profondità: 15, c: gini, mf: None, msl: 25):

	+ Tempo caricamento dataset: 0.034 sec
	+ Tempo addestramento modello: 11.444 sec
	+ TRAIN		ACCURANCY: 88.61%	LOG LOSS: 0.32991
	+ TEST		ACCURANCY: 86.13%	LOG LOSS: 1.1845
	+ TRAIN		MSE: 1.859
	+ TEST		MSE: 2.182

	+ Report di classificazione

              precision    recall  f1-score   support

           0       0.91      0.94      0.93       980
           1       0.93      0.96      0.95      1135
           2       0.84      0.84      0.84      1032
           3       0.82      0.81      0.82      1010
           4       0.86      0.85      0.85       982
           5       0.81      0.81      0.81       892
           6       0.88      0.85      0.87       958
           7       0.90      0.89      0.90      1028
           8       0.80      0.79      0.79       974
           9       0.84      0.84      0.84      1009

    accuracy                           0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


- Test del 2022-10-29 15:29:12 MNIST con Decision Tree (profondità: 17, c: gini, mf: None, msl: 25):

	+ Tempo caricamento dataset: 0.044 sec
	+ Tempo addestramento modello: 12.693 sec
	+ TRAIN		ACCURANCY: 88.61%	LOG LOSS: 0.32442
	+ TEST		ACCURANCY: 86.13%	LOG LOSS: 1.21708
	+ TRAIN		MSE: 1.859
	+ TEST		MSE: 2.183

	+ Report di classificazione

              precision    recall  f1-score   support

           0       0.91      0.94      0.93       980
           1       0.93      0.96      0.95      1135
           2       0.85      0.84      0.84      1032
           3       0.82      0.81      0.82      1010
           4       0.86      0.85      0.85       982
           5       0.81      0.81      0.81       892
           6       0.88      0.85      0.87       958
           7       0.90      0.89      0.90      1028
           8       0.80      0.79      0.79       974
           9       0.84      0.84      0.84      1009

    accuracy                           0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


- Test del 2022-10-29 15:31:41 MNIST con Decision Tree (profondità: 21, c: gini, mf: None, msl: 25):

	+ Tempo caricamento dataset: 0.037 sec
	+ Tempo addestramento modello: 12.533 sec
	+ TRAIN		ACCURANCY: 88.63%	LOG LOSS: 0.3177
	+ TEST		ACCURANCY: 86.15%	LOG LOSS: 1.25236
	+ TRAIN		MSE: 1.859
	+ TEST		MSE: 2.196

	+ Report di classificazione

              precision    recall  f1-score   support

           0       0.91      0.94      0.92       980
           1       0.93      0.96      0.95      1135
           2       0.85      0.84      0.84      1032
           3       0.82      0.81      0.82      1010
           4       0.86      0.85      0.85       982
           5       0.81      0.81      0.81       892
           6       0.88      0.85      0.87       958
           7       0.90      0.89      0.90      1028
           8       0.80      0.79      0.79       974
           9       0.84      0.84      0.84      1009

    accuracy                           0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


- Test del 2022-10-29 15:33:51 MNIST con Decision Tree (profondità: 25, c: gini, mf: None, msl: 25):

	+ Tempo caricamento dataset: 0.039 sec
	+ Tempo addestramento modello: 13.226 sec
	+ TRAIN		ACCURANCY: 88.63%	LOG LOSS: 0.3156
	+ TEST		ACCURANCY: 86.16%	LOG LOSS: 1.26076
	+ TRAIN		MSE: 1.859
	+ TEST		MSE: 2.183

	+ Report di classificazione

              precision    recall  f1-score   support

           0       0.91      0.94      0.92       980
           1       0.93      0.96      0.95      1135
           2       0.85      0.84      0.84      1032
           3       0.82      0.81      0.82      1010
           4       0.86      0.85      0.85       982
           5       0.81      0.81      0.81       892
           6       0.88      0.85      0.87       958
           7       0.90      0.89      0.90      1028
           8       0.80      0.79      0.80       974
           9       0.85      0.84      0.84      1009

    accuracy                           0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


- Test del 2022-10-29 15:36:36 MNIST con Decision Tree (profondità: 30, c: gini, mf: None, msl: 25):

	+ Tempo caricamento dataset: 0.038 sec
	+ Tempo addestramento modello: 13.452 sec
	+ TRAIN		ACCURANCY: 88.63%	LOG LOSS: 0.3147
	+ TEST		ACCURANCY: 86.15%	LOG LOSS: 1.28753
	+ TRAIN		MSE: 1.859
	+ TEST		MSE: 2.182

	+ Report di classificazione

              precision    recall  f1-score   support

           0       0.91      0.94      0.93       980
           1       0.93      0.96      0.95      1135
           2       0.84      0.84      0.84      1032
           3       0.82      0.81      0.82      1010
           4       0.86      0.85      0.85       982
           5       0.81      0.81      0.81       892
           6       0.88      0.85      0.87       958
           7       0.90      0.89      0.90      1028
           8       0.80      0.79      0.79       974
           9       0.85      0.84      0.84      1009

    accuracy                           0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


- Test del 2022-10-29 15:37:51 MNIST con Decision Tree (profondità: 35, c: gini, mf: None, msl: 25):

	+ Tempo caricamento dataset: 0.035 sec
	+ Tempo addestramento modello: 13.434 sec
	+ TRAIN		ACCURANCY: 88.63%	LOG LOSS: 0.31468
	+ TEST		ACCURANCY: 86.15%	LOG LOSS: 1.29051
	+ TRAIN		MSE: 1.859
	+ TEST		MSE: 2.182

	+ Report di classificazione

              precision    recall  f1-score   support

           0       0.91      0.94      0.93       980
           1       0.93      0.96      0.95      1135
           2       0.84      0.84      0.84      1032
           3       0.82      0.81      0.82      1010
           4       0.86      0.85      0.85       982
           5       0.81      0.81      0.81       892
           6       0.88      0.85      0.87       958
           7       0.90      0.89      0.90      1028
           8       0.80      0.79      0.79       974
           9       0.85      0.84      0.84      1009

    accuracy                           0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000

