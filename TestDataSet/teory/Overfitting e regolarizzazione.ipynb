{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting e regolarizzazione\n",
    "L'overfitting è un problema tipico del machine learning che si manifesta quando un modello si lega troppo ai dati di addestramento e fallisce nel generalizzare su dati nuovi.\n",
    "\n",
    "L'overffiting è caratterizzato da:\n",
    "* **Alta variaza**: le previsioni per modelli addestrati con diverse parti del dataset saranno molto diverse tra loro.\n",
    "* **Basso bias**: l'errore per le predizioni sul set di addestramento è mediamente molto basso.\n",
    "<img src=\"res/overfitting.png\" width=\"500px\" /><br>\n",
    "In questo notebook utilizzremo scikit-learn e il Boston Housing Dataset per studiare da vicino il problema dell'overfitting ed imparare a constrastarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerie necessarie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importiamo il dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  PRATIO  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0    15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0    17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0    17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0    18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0    18.7   \n",
       "\n",
       "        B  LSTAT  MEDV  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\", sep='\\s+', \n",
    "                     names=[\"CRIM\", \"ZN\",\"INDUS\",\"CHAS\",\"NOX\",\"RM\",\"AGE\",\"DIS\",\"RAD\",\"TAX\",\"PRATIO\",\"B\",\"LSTAT\",\"MEDV\"])\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston.drop('MEDV',axis=1).values\n",
    "Y = boston['MEDV'].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creiamo le features polinomiali\n",
    "Per correggere l'overfitting prima dobbiamo causarlo, un buon modo è aumentare la complessità del nostro modello aumentando il numero di features utilizzando i polinomi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di esempi nel test di addestramento: 354\n",
      "Numero di features: 105\n"
     ]
    }
   ],
   "source": [
    "polyfeats = PolynomialFeatures(degree=2)\n",
    "X_train_poly = polyfeats.fit_transform(X_train)\n",
    "X_test_poly = polyfeats.transform(X_test)\n",
    "\n",
    "print(\"Numero di esempi nel test di addestramento: \"+str(X_train_poly.shape[0]))\n",
    "print(\"Numero di features: \"+str(X_train_poly.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizziamo i dati\n",
    "**NOTA BENE** Per applicare la regolarizzazione è sempre necessario portare i dati sulla stessa scala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_poly = ss.fit_transform(X_train_poly)\n",
    "X_test_poly = ss.transform(X_test_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso il nostro set di addestramento contiene 354 e 105 features, abbastanza complesso !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Riconoscere l'overfitting\n",
    "Evidenziare un problema di overfitting è molto semplice, un modello che ne soffre avrà memorizzato la struttura dei dati di addestramento, piuttosto che imparare da essi, quindi l'errore per le predizioni sul train set sarà molto basso, invece fallirà nel generalizzare, perciò l'errore nel test set sarà decisamente più alto.<br><br>\n",
    "Quindi per riconoscere l'overfitting è sufficente confrontare questi due valori, scriviamo una funzione che ci permette di farlo in modo da non dover scrivere più volte lo stesso codice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overfit_eval(model, X, Y):\n",
    "    \n",
    "    \"\"\"\n",
    "    model: il nostro modello predittivo già addestrato\n",
    "    X: una tupla contenente le prorietà del train set e test set (X_train, X_test)\n",
    "    Y: una tupla contenente target del train set e test set (Y_train, Y_test)\n",
    "    \"\"\"\n",
    "    \n",
    "    Y_pred_train = model.predict(X[0])\n",
    "    Y_pred_test = model.predict(X[1])\n",
    "    \n",
    "    mse_train = mean_squared_error(Y[0], Y_pred_train)\n",
    "    mse_test = mean_squared_error(Y[1], Y_pred_test)\n",
    "\n",
    "    r2_train = r2_score(Y[0], Y_pred_train)\n",
    "    r2_test = r2_score(Y[1], Y_pred_test)    \n",
    "    \n",
    "    print(\"Train set:  MSE=\"+str(mse_train)+\" R2=\"+str(r2_train))\n",
    "    print(\"Test set:  MSE=\"+str(mse_test)+\" R2=\"+str(r2_test))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressione lineare non regolarizzata\n",
    "Cominciamo eseguendo una regressione lineare (in realtà si tratta di una regressione polinomiale) senza applicare la regolarizzazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:  MSE=4.116985074931631 R2=0.9514303225914079\n",
      "Test set:  MSE=29.550444547162407 R2=0.6451057885504222\n"
     ]
    }
   ],
   "source": [
    "ll = LinearRegression()\n",
    "ll.fit(X_train_poly, Y_train)\n",
    "\n",
    "overfit_eval(ll, (X_train_poly, X_test_poly),(Y_train, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il modello predice in maniera estremamente (o meglio dire eccessivamente) accurata i dati del train set, mentre è molto più scarso sul test set. Siamo di fronte ad un caso di overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regolarizzazione L2: Ridge Regression\n",
    "La ridge regression è un modello di regressione lineare che applica la **regolarizzazione L2**, la quale consiste nell'aggiungere una penalità per i pesi nella funzione di costo durante la fase di addestramento.<br>\n",
    "La penalità è data dalla somma dei quadrati dei pesi:\n",
    "$$\\lambda\\sum_{j=1}^{M}W_j^2$$<br>\n",
    "**Lambda** (conosciuto anche come **alpha**) è il **parametro di regolarizzazione** ed è un'altro iperparametro.\n",
    "Eseguiamo diverse Ridge regression per diversi valori di alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha=0.0001\n",
      "Train set:  MSE=4.099263404868843 R2=0.9516393920396632\n",
      "Test set:  MSE=28.917618463358185 R2=0.6527058878869307\n",
      "Alpha=0.001\n",
      "Train set:  MSE=4.113502509945512 R2=0.9514714077677813\n",
      "Test set:  MSE=28.420009267326737 R2=0.6586820627276777\n",
      "Alpha=0.01\n",
      "Train set:  MSE=4.208206127238454 R2=0.9503541522864941\n",
      "Test set:  MSE=26.813295018132663 R2=0.6779783405072717\n",
      "Alpha=0.1\n",
      "Train set:  MSE=4.747028830953716 R2=0.9439974508597079\n",
      "Test set:  MSE=23.63175511737236 R2=0.7161879211609108\n",
      "Alpha=1\n",
      "Train set:  MSE=5.875947305341872 R2=0.9306791596529944\n",
      "Test set:  MSE=17.634584627530085 R2=0.7882125937009261\n",
      "Alpha=10\n",
      "Train set:  MSE=8.81275552173788 R2=0.896032488585423\n",
      "Test set:  MSE=17.15971577477419 R2=0.7939156621191287\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "alphas = [0.0001, 0.001, 0.01, 0.1 ,1 ,10] #alpha corrispone a lambda\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(\"Alpha=\"+str(alpha))\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train_poly, Y_train)\n",
    "\n",
    "    overfit_eval(ridge, (X_train_poly, X_test_poly),(Y_train, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La Ridge regression, applicando la regolarizzazione L2, ci permette di ridurre l'overfitting e portare l'R2 fino ad un valore di 0.791 per alpha uguale a 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regolarizzazione L1: Lasso\n",
    "Lasso è un modello di regressione lineare che applica la regolarizzazione L1, questa funziona in egual modo alla L2, con la differenza che il termine di regolarizza sarà dato dalla somma del valore assoluto dei pesi:\n",
    "$$\\lambda\\sum_{j=1}^{M}|W_j|$$<br>\n",
    "e viene sempre applicato alla funzione di costo durante la fase di addestramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha=0.0001\n",
      "Train set:  MSE=5.391123652697102 R2=0.9363988132296843\n",
      "Test set:  MSE=29.701776720600787 R2=0.6432883230881463\n",
      "Alpha=0.001\n",
      "Train set:  MSE=5.407317548867123 R2=0.9362077675254491\n",
      "Test set:  MSE=28.78801855730653 R2=0.6542623536919963\n",
      "Alpha=0.01\n",
      "Train set:  MSE=6.0638588169003205 R2=0.9284622943178907\n",
      "Test set:  MSE=22.933242012656393 R2=0.7245769068863108\n",
      "Alpha=0.1\n",
      "Train set:  MSE=11.833211121207539 R2=0.860398996740507\n",
      "Test set:  MSE=19.29615234281638 R2=0.7682575380960781\n",
      "Alpha=1\n",
      "Train set:  MSE=21.59098506709198 R2=0.7452827346818105\n",
      "Test set:  MSE=27.25804314512913 R2=0.6726370152499754\n",
      "Alpha=10\n",
      "Train set:  MSE=84.76451346994796 R2=0.0\n",
      "Test set:  MSE=83.76673764512785 R2=-0.0060197319476869016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giuseppe/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "alphas = [0.0001, 0.001, 0.01, 0.1 ,1 ,10] #alpha corrisponde a lambda\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(\"Alpha=\"+str(alpha))\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train_poly, Y_train)\n",
    "\n",
    "    overfit_eval(lasso, (X_train_poly, X_test_poly),(Y_train, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso ci permette di ottenere un modello ancora migliore, con un R2 di 0.803 per Lambda uguale a 0.1.<br>\n",
    "Da notare che per valori di lambda più grandi il modello peggiora, questo perché l'effetto della regolarizzazione sarà molto pesante e buona parte dei pesi saranno portati a 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 ed L1 insieme: ElasticNet\n",
    "ElasticNet è un modello di regressione lineare che implementa entrambe le tecniche di regolarizzazone L2 ed L1.<br>\n",
    "Tramite il parametro <span style=\"font-family: Monaco\">l1_ration</span> possiamo controllare l'effetto delle due regolarizzazione\n",
    " * **<span style=\"font-family: Monaco\">l1_ration>0.5</span>** l'effetto della regolarizzazione L1 sarà più intenso rispetto alla L2.\n",
    " * **<span style=\"font-family: Monaco\">l1_ration<0.5</span>** l'effetto della regolarizzazione L2 sarà più intenso rispetto alla L1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda is: 0.0001\n",
      "Train set:  MSE=5.391059281137906 R2=0.9363995726460551\n",
      "Test set:  MSE=29.466017582883637 R2=0.6461197374561646\n",
      "Lambda is: 0.001\n",
      "Train set:  MSE=5.463124643400419 R2=0.9355493894819877\n",
      "Test set:  MSE=26.238997938658404 R2=0.6848755196286389\n",
      "Lambda is: 0.01\n",
      "Train set:  MSE=6.669947875220288 R2=0.921312025490655\n",
      "Test set:  MSE=15.78442472698635 R2=0.8104325991533365\n",
      "Lambda is: 0.1\n",
      "Train set:  MSE=12.092531251957979 R2=0.8573396960952863\n",
      "Test set:  MSE=20.123693597792272 R2=0.7583189532244381\n",
      "Lambda is: 1\n",
      "Train set:  MSE=21.178857007859765 R2=0.7501447700119411\n",
      "Test set:  MSE=27.923580301576486 R2=0.6646440632674491\n",
      "Lambda is: 10\n",
      "Train set:  MSE=70.28359861834348 R2=0.1708369960353573\n",
      "Test set:  MSE=69.68198552608109 R2=0.16313498207951238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giuseppe/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "alphas = [0.0001, 0.001, 0.01, 0.1 ,1 ,10]\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(\"Lambda is: \"+str(alpha))\n",
    "    elastic = ElasticNet(alpha=alpha, l1_ratio=0.5)\n",
    "    elastic.fit(X_train_poly, Y_train)\n",
    "    overfit_eval(elastic, (X_train_poly, X_test_poly),(Y_train, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizzando ElasticNet, e quindi entrambe le regolarizzazioni, abbiamo ottenuto un modello ancora migliore, con un R2 di 0.81 sul test set e 0.92 sul test set.<br>\n",
    "Abbiamo il nostro vincitore!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Che differenza c'è tra la regolarizzazione L2 ed L1 ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La differenza principale tra le due tecniche di regolarizzazione viste è la seguente:\n",
    "* La regolarizzazione L2 riduce la magnitudine dei pesi a valori più bassi.\n",
    "* La regolarizzazione L1 elimina le feature più deboli portando il loro peso a 0.\n",
    "Nella pratica la L2 porta quasi sempre a migliori risultati, ma utilizzarle entrambe con ElasticNet è anche un ottima soluzione."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
